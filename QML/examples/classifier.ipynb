{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "data = mnist['data']\n",
    "labels = np.array(mnist['target'], dtype=np.int8)\n",
    "\n",
    "labels_zero = labels[labels==0] \n",
    "labels_one = labels[labels==1] \n",
    "binary_labels = np.hstack((labels_zero, labels_one))\n",
    "digits_zero = data[labels==0]\n",
    "digits_one = data[labels==1]\n",
    "binary_digits = np.vstack((digits_zero, digits_one))\n",
    "        \n",
    "pca = PCA(n_components=4)\n",
    "sc = StandardScaler()\n",
    "binary_digits = sc.fit_transform(binary_digits)\n",
    "data = pca.fit_transform(binary_digits)\n",
    "data = (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, binary_labels, test_size=0.2)\n",
    "\n",
    "x_train=x_train[0:500]\n",
    "x_test=x_test[0:200]\n",
    "y_train=y_train[0:500]\n",
    "y_test=y_test[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 4), (200, 4), (500,), (200,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "qubit_count = 4\n",
    "\n",
    "@cudaq.kernel\n",
    "def encoding(qubit:cudaq.qvector, angles:list[float]):\n",
    "    # Define gates and the qubits they act upon.\n",
    "\n",
    "    qubit_num=qubit.size()\n",
    "    for i in range(qubit_num):\n",
    "        ry(angles[i], qubit[i])\n",
    "    \n",
    "    for i in range(qubit_num-1):\n",
    "        x.ctrl(qubit[i], qubit[i+1])\n",
    "\n",
    "@cudaq.kernel\n",
    "def training_layer(qubit:cudaq.qvector, alpha:list[float]):\n",
    "\n",
    "    qubit_num=qubit.size()\n",
    "\n",
    "    count=0\n",
    "    for i in range(qubit_num):\n",
    "        u3(alpha[count],alpha[count+1],alpha[count+2], qubit[i])\n",
    "        count+=3\n",
    "    \n",
    "    for i in range(qubit_num-1):\n",
    "        x.ctrl(qubit[i], qubit[i+1])\n",
    "    \n",
    "    x.ctrl(qubit[qubit_num-1], qubit[0])\n",
    "\n",
    "    for i in range(qubit_num):\n",
    "        u3(alpha[count],alpha[count+1],alpha[count+2], qubit[i])\n",
    "        count+=3\n",
    "\n",
    "    for i in range(qubit_num//2):\n",
    "        x.ctrl(qubit[i], qubit[i+2])\n",
    "    \n",
    "    for i in range(qubit_num-1, qubit_num//2-1, -1):\n",
    "        x.ctrl(qubit[i], qubit[i-2])\n",
    "\n",
    "@cudaq.kernel\n",
    "def main_kernel(qubit_count:int, angles: list[float],alpha:list[float]):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qvector(qubit_count)\n",
    "\n",
    "    # encoding data\n",
    "    encoding(qubit,angles)\n",
    "    \n",
    "    # training layer\n",
    "    training_layer(qubit,alpha)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "ham = cudaq.spin.z(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5604735340341649, -0.4343701128131203, 2.034773553111448, 4.78473940808937, -0.7356145218440903, -0.7355629438854153, 4.961243379652874, 2.410967307216451, -1.474897281901825, 1.7045026470610245, -1.4558696192831628, -1.4631331723745038, 0.7601468947977512, -6.01074716087542, -5.418989190668973, -1.7664783710685958, -3.1819028069697457, 0.9872371114915007, -2.8526417649400995, -4.436882932752625, 4.604471405186879, -0.709297166963182, 0.21214611175768935, -4.4759784350235785, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "alpha=np.random.normal(0, np.pi, 3*(qubit_count*2))\n",
    "alpha=alpha.tolist()\n",
    "\n",
    "bias=[0.0]\n",
    "alpha=alpha+bias\n",
    "\n",
    "print(alpha)\n",
    "n=len(alpha)\n",
    "print(alpha[n-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(main_kernel, ham,qubit_count,angles,alpha):\n",
    "    expectation_value = cudaq.observe(main_kernel, ham, qubit_count,angles,alpha).expectation()\n",
    "    return expectation_value\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss(alpha, main_kernel, ham, qubit_count, x_train):\n",
    "    pred=[]\n",
    "\n",
    "    param=alpha[0:n-2]\n",
    "    for image in range (10):\n",
    "    \n",
    "        eig=cost(main_kernel, ham, qubit_count, x_train[image], param)\n",
    "        pred.append(eig+alpha[n-1])\n",
    "\n",
    "    #print(pred)\n",
    "    #print(y_train[:10])\n",
    "\n",
    "    return square_loss(y_train[:10],pred)\n",
    "\n",
    "def variational_classifier(alpha,main_kernel,ham,qubit_count,data_img):\n",
    "    \n",
    "    param=alpha[0:n-2]\n",
    "    \n",
    "    pred=cost(main_kernel, ham, qubit_count,data_img, param)+alpha[n-1]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "#res=loss(alpha, main_kernel, ham, qubit_count, x_train)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Cost:  0.10558979009100877\n",
      "accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_opt=scipy.optimize.minimize(loss, alpha, method='COBYLA', args=(main_kernel, ham, qubit_count, x_train), tol=1e-5)\n",
    "\n",
    "#print('Final loss', result_opt.fun)\n",
    "#print('Opt. parameters', result_opt.x)\n",
    "alpha=result_opt.x\n",
    "\n",
    "predictions = [np.sign(variational_classifier(alpha,main_kernel,ham,qubit_count,x_train[i])) for i in range(10)]\n",
    "print(predictions)\n",
    "   \n",
    "acc = accuracy(y_train[:10], predictions)\n",
    "\n",
    "c=loss(alpha, main_kernel, ham, qubit_count, x_train)\n",
    "\n",
    "print('Cost: ', c)\n",
    "print('accuracy: ', acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
